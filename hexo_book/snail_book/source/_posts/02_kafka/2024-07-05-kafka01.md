---
title: kafka架构理解和基本概念
toc: true
date: 2024-07-05 16:26:02
tags: Kafka
categories: [大数据]
---

# 为什么要用消息队列
1. 解耦
允许你独立的扩展或修改两边的处理过程, 只要确保它们遵守同样的接口约束.
2. 可恢复性
系统的一部分组件失效时, 不会影响到整个系统. 消息队列降低了进程间的耦合度, 所以即使一个处理
消息的进程挂掉, 加入队列中的消息仍然可以在系统恢复后被处理.
3. 缓冲
有助于控制和优化数据流经过系统的速度, 解决生产消息和消费消息的处理速度不一致的情况.
4. 灵活性与峰值处理能力
在访问量剧增的情况下, 应用仍然需要继续发挥作用, 但是这样的突发流量并不常见. 如果为以能处理
这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费. 使用消息队列能够使关键组件顶住突发的
访问压力, 而不会因为突发的超负荷的请求而完全崩溃.
5. 异步通信
很多时候, 用户不想也不需要立即处理消息. 消息队列提供了异步处理机制, 允许用户把一个消息放入
队列, 但并不立即处理它. 想向队列中放入多少消息就放多少, 然后在需要的时候再去处理它们.

# Kafka适合以下应用场景
1. 日志收集：一个公司可以用Kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放
给各种consumer.
2. 消息系统：解耦生产者和消费者、缓存消息等。
3. 用户活动跟踪：kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击
等活动, 这些活动信息被各个服务器发布到kafka的topic中, 然后消费者通过订阅这些topic来做实
时的监控分析, 亦可保存到数据库.
4. 运营指标：kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作
的集中反馈, 比如报警和报告; 
5. 流式处理：比如spark和flink。
# 基本概念
1. Producer ：消息生产者，就是向kafka broker发消息的客户端。
2. Consumer ：消息消费者，向kafka broker取消息的客户端。
3. Consumer Group （CG）：消费者组，由多个consumer组成。消费者组内每个消费者负责消费不同分区的数据, 一个分区只能由一个组内消费者消费; 消费者组之间互不影响. 所有的消费者都属于某个消费者组, 即**消费者组是逻辑上的一个订阅者**.
4. Broker ：一台kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic.
5. Topic ：可以理解为一个队列，生产者和消费者面向的都是一个topic。
6. Partition：为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，一个topic可以分为多个partition, **每个partition是一个有序的队列**.
7. Replica：副本，为保证集群中的某个节点发生故障时，该节点上的partition数据不丢失，且kafka仍然能够继续工作, kafka提供了副本机制, 一个topic的每个分区都有若干个副本, 一个leader和若干个follower.
8. leader：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是leader.
9. follower：每个分区多个副本中的“从”，实时从leader中同步数据，保持和leader数据的同步。leader发生故障时, 某个follower会成为新的follower.
# kafka为什么要分区
1. 方便在集群中扩展，每个Partition可以通过调整以适应它所在的机器，而一个topic又可以有多个
Partition组成, 因此整个集群就可以适应任意大小的数据了.
1. 可以提高并发，因为可以以Partition为单位读写。
# Kafka生产者分区策略
1. 指明 partition 的情况下，直接将指明的值直接作为partiton值。
2. 没有指明partition值但有key的情况下，将key的hash值与topic的partition数进行取余得到
partition值.
1. 既没有partition值又没有key值的情况下，第一次调用时随机生成一个整数(后面每次调用在这个
整数上自增), 将这个值与topic可用的partition总数取余得到partition值, 也就是常说的round-robin算法.

# kafka的数据可靠性怎么保证

为保证producer发送的数据, 能可靠的发送到指定的topic, topic的每个partition收到producer发送的
数据后, 都需要向producer发送ack(acknowledgement确认收到), 如果producer收到ack, 就会进
行下一轮的发送, 否则重新发送数据. 所以引出ack机制.

# 数据重复和丢失问题

Kafka为用户提供了三种可靠性级别, 用户根据对可靠性和延迟的要求进行权衡, 选择以下的配置.

acks参数配置:

* 0:producer不等待broker的ack, 这一操作提供了一个最低的延迟, broker一接收到还没有写入磁盘就已经返回, 当broker故障时有可能丢失数据.
* 1:producer等待broker的ack, partition的leader落盘成功后返回ack, 如果在follower同步成功之前leader故障, 那么将会丢失数据.
* -1(all):producer等待broker的ack, partition的leader和follower全部落盘成功后才返回ack.
但是如果在follower同步完成后, broker发送ack之前, leader发生故障, 那么会造成数据重复.

# Kafka消费能力不足怎么处理
1. 如果是Kafka消费能力不足，则可以考虑增加Topic的分区数，并且同时提升消费组的消费者数量，
消费者数=分区数.(两者缺一不可)
2. 如果是下游的数据处理不及时：提高每批次拉取的数量。批次拉取数据过少（拉取数据/处理时间<
生产速度), 使处理的数据小于生产的数据, 也会造成数据积压.

# Kafka中的数据是有序的吗

单分区内有序.
多分区, 分区与分区间无序.

# Kafka可以按照时间消费数据吗

可以, 提供的API方法:
KafkaUtil.fetchOffsetsWithTimestamp(topic, sTime, kafkaProp)

# Kafka单条日志传输大小

kafka对于消息体的大小默认为单条最大值是1M但是在我们应用场景中, 常常会出现一条消息大于1M, 
如果不对kafka进行配置. 则会出现生产者无法将消息推送到kafka或消费者无法去消费kafka里面的数
据, 这时我们就要对kafka进行以下配置:server.properties

```shell
replica.fetch.max.bytes: 1048576 # broker可复制的消息的最大字节数, 默认为1M
message.max.bytes: 1000012 # kafka 会接收单个消息size的最大限制， 默认为1M左右
# 注意 message.max.bytes必须小于等于replica.fetch.max.bytes，否则就会导致replica之间数据同步失败
```

# 引用
1. [kafka官方中文文档](https://kafka1x.apachecn.org/) 
2. 公众号: 大数据左右手
3. [超详细的Kafka教程-从部署到开发到原理都有讲解](https://cloud.tencent.com/developer/article/1991788)
