<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Snail Book</title>
  
  <subtitle>Snail 的知识库</subtitle>
  <link href="https://champion-yang.github.io/atom.xml" rel="self"/>
  
  <link href="https://champion-yang.github.io/"/>
  <updated>2024-09-25T08:19:13.297Z</updated>
  <id>https://champion-yang.github.io/</id>
  
  <author>
    <name>Sanil</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>05软件工程</title>
    <link href="https://champion-yang.github.io/2024/09/25/05_%E8%BD%AF%E8%80%83/01_%E4%B8%AD%E9%A1%B9/05%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/"/>
    <id>https://champion-yang.github.io/2024/09/25/05_%E8%BD%AF%E8%80%83/01_%E4%B8%AD%E9%A1%B9/05%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/</id>
    <published>2024-09-25T08:15:44.000Z</published>
    <updated>2024-09-25T08:19:13.297Z</updated>
    
    <content type="html"><![CDATA[<h1 id="软件需求"><a href="#软件需求" class="headerlink" title="软件需求:"></a>软件需求:</h1><p>(1) 是指用户对系统在功能、 行为、 性能、 设计约束等方面的期望.<br>(2) 需求是多层次的, 包括业务需求、 用户需求和系统需求, 这 3 个不同层次的需求从目标到具体, 从整体到局部, 从概念到细节.<br>①业务需求: 是指反映组织机构或用户对系统、 产品高层次的目标要求, 从总体上描述了为什么要达到某种效应, 组织希望达到什么目标.<br>②用户需求: 描述的是用户的具体目标, 或用户要求系统必须能完成的任务和想要达到的结果, 这构成了用户原始需求文档的内容.<br>③系统需求: 是从系统的角度来说明软件的需求, 包括功能需求、 非功能需求和约束等.</p><h1 id="结构化分析-SA-方法"><a href="#结构化分析-SA-方法" class="headerlink" title="结构化分析( SA) 方法:"></a>结构化分析( SA) 方法:</h1><p>给出一组帮助系统分析人员产生功能规约的原理与技术, 其建立模型的核心是数据字典. 围绕这个核心, 有 3 个层次的模型, 分别是数据模型、 功能模型和行为模型(状态模型) . </p><p>一般使用实体关系图(E-R图) 表示数据模型, 用数据流图( DFD) 表示功能模型, 用状态转换图( STD)表示行为模型.<br>(1) E-R 图主要描述实体、 属性, 以及实体之间的关系;<br>(2) DFD 从数据传递和加工的角度, 利用图形符号通过逐层细分描述系统内各个部件的功能和数据在它们之间传递的情况, 来说明系统所完成的功能;<br>(3) STD通过描述系统的状态和引起系统状态转换的事件, 来表示系统的行为, 指出作为特定事件的结果将执行哪些动作( 例如处理数据等)</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;软件需求&quot;&gt;&lt;a href=&quot;#软件需求&quot; class=&quot;headerlink&quot; title=&quot;软件需求:&quot;&gt;&lt;/a&gt;软件需求:&lt;/h1&gt;&lt;p&gt;(1) 是指用户对系统在功能、 行为、 性能、 设计约束等方面的期望.&lt;br&gt;(2) 需求是多层次的, 包括业务需求、 </summary>
      
    
    
    
    <category term="软考" scheme="https://champion-yang.github.io/categories/%E8%BD%AF%E8%80%83/"/>
    
    <category term="中项" scheme="https://champion-yang.github.io/categories/%E8%BD%AF%E8%80%83/%E4%B8%AD%E9%A1%B9/"/>
    
    
    <category term="软考" scheme="https://champion-yang.github.io/tags/%E8%BD%AF%E8%80%83/"/>
    
  </entry>
  
  <entry>
    <title>linux双网卡配置</title>
    <link href="https://champion-yang.github.io/2024/09/25/07_linux/2024-09-25-linux%E5%8F%8C%E7%BD%91%E5%8D%A1%E9%85%8D%E7%BD%AE/"/>
    <id>https://champion-yang.github.io/2024/09/25/07_linux/2024-09-25-linux%E5%8F%8C%E7%BD%91%E5%8D%A1%E9%85%8D%E7%BD%AE/</id>
    <published>2024-09-25T06:47:57.000Z</published>
    <updated>2024-09-25T08:26:41.494Z</updated>
    
    <content type="html"><![CDATA[<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><ol><li>只有一个网卡能访问<br>Linux默认启用了反向路由检查</li></ol><p>如果2个网卡在一个Lan里面, 那么服务器可能从eth0或者eth1发现网关, 如果一个包从eth0进入了, 而网关在eth1上, 那么从eth1是出不去的, 就不通了.  反向路由检查要求从哪里来的才能回哪去.<br>关闭反向路由检查(根据自己的情况替换第二第三行的网卡名):</p><p>echo 0 &gt; &#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;conf&#x2F;all&#x2F;rp_filter<br>echo 0 &gt; &#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;conf&#x2F;ens192&#x2F;rp_filter<br>echo 0 &gt; &#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;conf&#x2F;ens224&#x2F;rp_filter</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;只有一个网卡能访问&lt;br&gt;Linux默认启用了反向路由检查&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;如果2个网卡在一个Lan里面, 那么服务</summary>
      
    
    
    
    <category term="linux" scheme="https://champion-yang.github.io/categories/linux/"/>
    
    
    <category term="linux" scheme="https://champion-yang.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>linux部署 hexo</title>
    <link href="https://champion-yang.github.io/2024/07/25/07_linux/2024-07-25-linux%E9%83%A8%E7%BD%B2hexo/"/>
    <id>https://champion-yang.github.io/2024/07/25/07_linux/2024-07-25-linux%E9%83%A8%E7%BD%B2hexo/</id>
    <published>2024-07-25T02:47:57.000Z</published>
    <updated>2024-07-25T06:53:52.856Z</updated>
    
    <content type="html"><![CDATA[<ol><li>新建hexo用户</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">useradd -m -d /home/hexoadmin hexoadmin</span><br></pre></td></tr></table></figure><p>1. </p>]]></content>
    
    
      
      
    <summary type="html">&lt;ol&gt;
&lt;li&gt;新建hexo用户&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;t</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>linux路由配置转发策略</title>
    <link href="https://champion-yang.github.io/2024/07/25/07_linux/2024-07-25-linux%E8%B7%AF%E7%94%B1%E9%85%8D%E7%BD%AE%E8%BD%AC%E5%8F%91%E7%AD%96%E7%95%A5/"/>
    <id>https://champion-yang.github.io/2024/07/25/07_linux/2024-07-25-linux%E8%B7%AF%E7%94%B1%E9%85%8D%E7%BD%AE%E8%BD%AC%E5%8F%91%E7%AD%96%E7%95%A5/</id>
    <published>2024-07-25T02:47:57.000Z</published>
    <updated>2024-07-25T02:48:14.259Z</updated>
    
    
    
    
    
  </entry>
  
  <entry>
    <title>2024-07-18-api测试思路及体系构建</title>
    <link href="https://champion-yang.github.io/2024/07/18/06_%E5%85%B6%E4%BB%96/2024-07-18-api%E6%B5%8B%E8%AF%95%E6%80%9D%E8%B7%AF%E5%8F%8A%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"/>
    <id>https://champion-yang.github.io/2024/07/18/06_%E5%85%B6%E4%BB%96/2024-07-18-api%E6%B5%8B%E8%AF%95%E6%80%9D%E8%B7%AF%E5%8F%8A%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/</id>
    <published>2024-07-18T02:32:37.000Z</published>
    <updated>2024-07-18T02:32:37.559Z</updated>
    
    
    
    
    
  </entry>
  
  <entry>
    <title>02信息技术发展</title>
    <link href="https://champion-yang.github.io/2024/07/17/05_%E8%BD%AF%E8%80%83/01_%E4%B8%AD%E9%A1%B9/02%E4%BF%A1%E6%81%AF%E6%8A%80%E6%9C%AF%E5%8F%91%E5%B1%95/"/>
    <id>https://champion-yang.github.io/2024/07/17/05_%E8%BD%AF%E8%80%83/01_%E4%B8%AD%E9%A1%B9/02%E4%BF%A1%E6%81%AF%E6%8A%80%E6%9C%AF%E5%8F%91%E5%B1%95/</id>
    <published>2024-07-17T03:21:35.000Z</published>
    <updated>2024-07-17T03:25:00.750Z</updated>
    
    <content type="html"><![CDATA[<h1 id="信息技术发展"><a href="#信息技术发展" class="headerlink" title="信息技术发展"></a>信息技术发展</h1><h2 id="信息技术及其发展"><a href="#信息技术及其发展" class="headerlink" title="信息技术及其发展"></a>信息技术及其发展</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;信息技术发展&quot;&gt;&lt;a href=&quot;#信息技术发展&quot; class=&quot;headerlink&quot; title=&quot;信息技术发展&quot;&gt;&lt;/a&gt;信息技术发展&lt;/h1&gt;&lt;h2 id=&quot;信息技术及其发展&quot;&gt;&lt;a href=&quot;#信息技术及其发展&quot; class=&quot;headerlink&quot; </summary>
      
    
    
    
    <category term="软考" scheme="https://champion-yang.github.io/categories/%E8%BD%AF%E8%80%83/"/>
    
    <category term="中项" scheme="https://champion-yang.github.io/categories/%E8%BD%AF%E8%80%83/%E4%B8%AD%E9%A1%B9/"/>
    
    
    <category term="软考" scheme="https://champion-yang.github.io/tags/%E8%BD%AF%E8%80%83/"/>
    
  </entry>
  
  <entry>
    <title>01信息化发展</title>
    <link href="https://champion-yang.github.io/2024/07/16/05_%E8%BD%AF%E8%80%83/01_%E4%B8%AD%E9%A1%B9/01%E4%BF%A1%E6%81%AF%E5%8C%96%E5%8F%91%E5%B1%95/"/>
    <id>https://champion-yang.github.io/2024/07/16/05_%E8%BD%AF%E8%80%83/01_%E4%B8%AD%E9%A1%B9/01%E4%BF%A1%E6%81%AF%E5%8C%96%E5%8F%91%E5%B1%95/</id>
    <published>2024-07-16T08:48:44.000Z</published>
    <updated>2024-07-16T10:49:58.342Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/../../../images/ruankao/01-%E4%BF%A1%E6%81%AF%E5%8C%96%E5%8F%91%E5%B1%95.png" alt="img"></p><h1 id="信息化发展"><a href="#信息化发展" class="headerlink" title="信息化发展"></a>信息化发展</h1><h2 id="信息与信息化"><a href="#信息与信息化" class="headerlink" title="信息与信息化"></a>信息与信息化</h2><h3 id="信息的特征"><a href="#信息的特征" class="headerlink" title="信息的特征"></a>信息的特征</h3><p>客观、普遍、无限、动态、相对、依附、变换、传递、层次、系统、转化</p><h3 id="信息的质量"><a href="#信息的质量" class="headerlink" title="信息的质量"></a>信息的质量</h3><p>精确、完整、可报、及时、经济、可验证、安全</p><p>信息具有价值, 价值由质量决定</p><h3 id="信息系统生命周期-类比软件生命周期"><a href="#信息系统生命周期-类比软件生命周期" class="headerlink" title="信息系统生命周期(类比软件生命周期)"></a>信息系统生命周期(类比软件生命周期)</h3><p><strong>简化为:</strong></p><pre><code>- 立项【规划】- 开发【分析、设计、实施】- 运维- 消亡</code></pre><ol><li><p>系统规划(可行性分析与项目开发计划)</p><ul><li><p>系统建设的必要性和可能性</p></li><li><p>可行性研究报告</p></li><li><p>系统设计任务书</p><ul><li><p>系统建设方案</p></li><li><p>实施计划</p></li></ul></li></ul></li><li><p>系统分析(需求分析)</p><ul><li><p>逻辑设计阶段, 输出系统说明书, 和用户确认需求的基础</p></li><li><p>系统设计和验收的依据</p></li></ul></li><li><p>系统设计(概要设计、详细设计)</p><ul><li><p>解决”怎么做”的问题, 物理模型</p></li><li><p>设计材料</p></li></ul></li><li><p>系统实施(编码、测试)</p></li><li><p>系统运行和维护(维护)</p></li></ol><h3 id="国家信息化体系"><a href="#国家信息化体系" class="headerlink" title="国家信息化体系"></a>国家信息化体系</h3><table><thead><tr><th>内容</th><th>地位</th><th>速记</th></tr></thead><tbody><tr><td>信息资源</td><td>核心任务</td><td>资源任务</td></tr><tr><td>信息网络</td><td>基础设施</td><td>网络基础</td></tr><tr><td>信息技术应用</td><td>龙头</td><td>应用龙头</td></tr><tr><td>信息技术和产业</td><td>物质基础</td><td>技术产业为物基</td></tr><tr><td>信息化人才</td><td>成功之本</td><td>人本</td></tr><tr><td>政策法规和标准规范</td><td>保障</td><td>规保</td></tr></tbody></table><h3 id="国家信息化体系-十四五"><a href="#国家信息化体系-十四五" class="headerlink" title="国家信息化体系(十四五)"></a>国家信息化体系(十四五)</h3><p>数据治理</p><p>密码区块链</p><p>信息互联互通</p><p>智能网联</p><p>网络安全</p><h2 id="现代化基础设施"><a href="#现代化基础设施" class="headerlink" title="现代化基础设施"></a>现代化基础设施</h2><h3 id="新基建"><a href="#新基建" class="headerlink" title="新基建"></a>新基建</h3><table><thead><tr><th>分类</th><th>内容</th><th>特点</th></tr></thead><tbody><tr><td>信息基础设施</td><td>通、新、算</td><td>技术新</td></tr><tr><td>融合基础设施</td><td>利用大数据、人工智能支持传统设施转型</td><td>应用新</td></tr><tr><td>创新技术设施</td><td>科研开发等公益属性</td><td>平台新</td></tr></tbody></table><h3 id="工业互联网"><a href="#工业互联网" class="headerlink" title="工业互联网"></a>工业互联网</h3><p>网络为基础、平台为中枢、数据为要素、安全为保障</p><h3 id="城市物联网"><a href="#城市物联网" class="headerlink" title="城市物联网"></a>城市物联网</h3><p>智慧物流、交通、安防、能源环保、医疗、建筑、家居、零售</p><h2 id="产业现代化"><a href="#产业现代化" class="headerlink" title="产业现代化"></a>产业现代化</h2><h3 id="农业农村现代化"><a href="#农业农村现代化" class="headerlink" title="农业农村现代化"></a>农业农村现代化</h3><p>加强基础设施建设</p><p>发展智慧农业</p><p>建设数字乡村</p><h3 id="工业现代化"><a href="#工业现代化" class="headerlink" title="工业现代化"></a>工业现代化</h3><p>信息化和工业化结合</p><ul><li>技术融合、产品融合、业务融合、产业衍生</li></ul><p>智能制造</p><ul><li>能力成熟度模型<table><thead><tr><th>级别</th><th>内容</th><th>特点</th></tr></thead><tbody><tr><td>一级</td><td>规划</td><td></td></tr><tr><td>二级</td><td>规范</td><td></td></tr><tr><td>三级</td><td>集成</td><td>共享</td></tr><tr><td>四级</td><td>优化</td><td>预测</td></tr><tr><td>五级</td><td>引领</td><td></td></tr></tbody></table></li></ul><h3 id="服务现代化"><a href="#服务现代化" class="headerlink" title="服务现代化"></a>服务现代化</h3><p>消费互联网</p><ul><li>媒体属性、产业属性</li></ul><h2 id="数字中国"><a href="#数字中国" class="headerlink" title="数字中国"></a>数字中国</h2><h3 id="数字经济"><a href="#数字经济" class="headerlink" title="数字经济"></a>数字经济</h3><p>数字产业化</p><p>产业数字化</p><p>数字化治理</p><p>数据价值化</p><h3 id="数字政府"><a href="#数字政府" class="headerlink" title="数字政府"></a>数字政府</h3><p>一网通办</p><p>跨省通办</p><p>一网通管</p><h3 id="数字社会"><a href="#数字社会" class="headerlink" title="数字社会"></a>数字社会</h3><h3 id="数字生态"><a href="#数字生态" class="headerlink" title="数字生态"></a>数字生态</h3><h2 id="数字化转型与元宇宙"><a href="#数字化转型与元宇宙" class="headerlink" title="数字化转型与元宇宙"></a>数字化转型与元宇宙</h2><h3 id="元宇宙"><a href="#元宇宙" class="headerlink" title="元宇宙"></a>元宇宙</h3><p>沉浸式体验</p><p>虚拟身份</p><p>虚拟经济</p><p>虚拟社会治理</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;img src=&quot;/../../../images/ruankao/01-%E4%BF%A1%E6%81%AF%E5%8C%96%E5%8F%91%E5%B1%95.png&quot; alt=&quot;img&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;信息化发展&quot;&gt;&lt;a href=&quot;#信息化发展&quot; c</summary>
      
    
    
    
    <category term="软考" scheme="https://champion-yang.github.io/categories/%E8%BD%AF%E8%80%83/"/>
    
    <category term="中项" scheme="https://champion-yang.github.io/categories/%E8%BD%AF%E8%80%83/%E4%B8%AD%E9%A1%B9/"/>
    
    
    <category term="软考" scheme="https://champion-yang.github.io/tags/%E8%BD%AF%E8%80%83/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch 操作API</title>
    <link href="https://champion-yang.github.io/2024/07/11/03_es/2024-07-11-escrud/"/>
    <id>https://champion-yang.github.io/2024/07/11/03_es/2024-07-11-escrud/</id>
    <published>2024-07-11T07:55:29.000Z</published>
    <updated>2024-07-11T08:34:32.447Z</updated>
    
    <content type="html"><![CDATA[<h1 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h1><h2 id="集群健康状态"><a href="#集群健康状态" class="headerlink" title="集群健康状态"></a>集群健康状态</h2><p> <code>GET /_cat/health?v</code></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;epoch&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1720686430&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;timestamp&quot;</span><span class="punctuation">:</span> <span class="string">&quot;08:27:10&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;cluster&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ISOP_1713495047759&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;status&quot;</span><span class="punctuation">:</span> <span class="string">&quot;yellow&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;node.total&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;node.data&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;shards&quot;</span><span class="punctuation">:</span> <span class="string">&quot;75&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;pri&quot;</span><span class="punctuation">:</span> <span class="string">&quot;75&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;relo&quot;</span><span class="punctuation">:</span> <span class="string">&quot;0&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;init&quot;</span><span class="punctuation">:</span> <span class="string">&quot;0&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;unassign&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;pending_tasks&quot;</span><span class="punctuation">:</span> <span class="string">&quot;0&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;max_task_wait_time&quot;</span><span class="punctuation">:</span> <span class="string">&quot;-&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;active_shards_percent&quot;</span><span class="punctuation">:</span> <span class="string">&quot;98.7%&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>title</th><th>title</th><th>title</th></tr></thead><tbody><tr><td>conte</td><td>conte</td><td>conte</td></tr></tbody></table><h1 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h1><h2 id="索引操作"><a href="#索引操作" class="headerlink" title="索引操作"></a>索引操作</h2><h2 id="文档操作"><a href="#文档操作" class="headerlink" title="文档操作"></a>文档操作</h2><h3 id="增"><a href="#增" class="headerlink" title="增"></a>增</h3><h3 id="删"><a href="#删" class="headerlink" title="删"></a>删</h3><h3 id="改"><a href="#改" class="headerlink" title="改"></a>改</h3><h3 id="查"><a href="#查" class="headerlink" title="查"></a>查</h3><blockquote><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/elasticsearch-intro.html">https://www.elastic.co/guide/en/elasticsearch/reference/current/elasticsearch-intro.html</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;集群&quot;&gt;&lt;a href=&quot;#集群&quot; class=&quot;headerlink&quot; title=&quot;集群&quot;&gt;&lt;/a&gt;集群&lt;/h1&gt;&lt;h2 id=&quot;集群健康状态&quot;&gt;&lt;a href=&quot;#集群健康状态&quot; class=&quot;headerlink&quot; title=&quot;集群健康状态&quot;&gt;&lt;/a&gt;集</summary>
      
    
    
    
    <category term="大数据" scheme="https://champion-yang.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    <category term="存储" scheme="https://champion-yang.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%AD%98%E5%82%A8/"/>
    
    
    <category term="Elasticsearch" scheme="https://champion-yang.github.io/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch 相关概念</title>
    <link href="https://champion-yang.github.io/2024/07/10/03_es/2024-07-10-es%E6%A6%82%E5%BF%B5%E7%9B%B8%E5%85%B3/"/>
    <id>https://champion-yang.github.io/2024/07/10/03_es/2024-07-10-es%E6%A6%82%E5%BF%B5%E7%9B%B8%E5%85%B3/</id>
    <published>2024-07-10T07:55:29.000Z</published>
    <updated>2024-07-11T03:22:58.583Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ES-是什么、干什么用的"><a href="#ES-是什么、干什么用的" class="headerlink" title="ES 是什么、干什么用的"></a>ES 是什么、干什么用的</h1><ol><li>分布式的搜索引擎和数据分析引擎<ol><li>搜索业务, 类比于 mysql, 可以进行数据查询, 包括全文检索, 结构化检索等. 还支持部分匹配搜索, 搜索纠错, 搜索推荐等; Elasticsearch作为传统数据库的一个补充, 提供了数据库所不不能提供的很多功能</li><li>数据分析业务, 通过对数据查询的结果进行分组聚合等操作, 完成数据分析的工作</li></ol></li><li>对海量数据进行近实时的处理<ol><li>分布式: ES自动可以将海量数据分散到多台服务器上去存储和检索</li><li>近实时: 检索个数据要花费1小时(这就不是近实时, 是离线批处理, batch-processing); 在秒级别对数据进行搜索和分析</li></ol></li></ol><p>将全文检索(lucene)、数据分析以及分布式技术合并到一起形成了 ES.</p><h1 id="一些概念"><a href="#一些概念" class="headerlink" title="一些概念"></a>一些概念</h1><ul><li>Near Realtime(NRT)近实时: 从写入数据到数据可以被搜索到有一个小延迟(大概1秒); </li><li>Cluster 集群: 通过网络, 利用软件将多台低成本的计算机的资源统一进行协调调度, 从而实现一台”超级计算机”, 由一个或多个节点组成</li><li>Node 节点: 单个 es 的实例, 通常一个节点运行在一个隔离的容器或虚拟机中</li><li>Document&amp;field 文档: Document相当于mysql中的一行, 是es中最小的数据单元; field 相当于mysql中的字段</li><li>Index 索引: 相当于mysql中的数据库</li><li>Type 类型: 一个 index 索引中可以存在多个 type, 可类比于关系型数据库中的”表”的概念, 但是这个使用的范围比较受限, 从表现形式来说, 他是在 doc 文档上通过 _type 字段来进行区分, 则不同 type 里的字段需要保持一致. 所以有说法是 _type 是 es 早期设计的缺陷. 在5.x以前的版本里边, 一个index下面是支持多个type的, 在6.x的版本里改为一个index只支持一个type, type可以自定义.7.x的版本所有的type默认为_doc(自定义type也能用, 但是会提示不推荐)</li><li>shard 分片: 单台机器无法存储大量数据, es 可以将一个索引中的数据切分为多个 shard, 分布在多台服务器上存储. 有了 shard 就可以横向扩展, 存储更多数据, 让搜索和分析等操作分布到多台服务器上去执行, 提升吞吐量和性能.</li><li>replica 复制集&#x2F;副本: 每个 shard 可以创建多个 replica副本.replica 可以在 shard 故障时提供备用服务, 保证数据不丢失, 多个 replica 还可以提升搜索操作的吞吐量和性能.</li></ul><h1 id="lucene"><a href="#lucene" class="headerlink" title="lucene"></a>lucene</h1><p>Lucene 是一个开放源码的全文检索引擎工具包, 提供了完整的查询引擎和索引引擎, 部分语种文本分析引擎, 并不是一个完整的全文检索引擎, 仅提供了全文检索引擎架构, 可以作为一个工具包结合各类插件为项目提供部分高性能的全文检索功能; 现在常用的 ElasticSearch、Solr 等全文搜索引擎均是基于 Lucene 实现的.</p><h2 id="倒排索引"><a href="#倒排索引" class="headerlink" title="倒排索引"></a>倒排索引</h2><blockquote><p>倒排索引(英语: Inverted index), 也常被称为反向索引、置入档案或反向档案, 是一种索引方法, 被用来存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射. 它是文档检索系统中最常用的数据结构.[维基百科]</p></blockquote><p><strong>正向索引:</strong> 正向索引是基于文档建立的, 它记录文档中每个单词的位置信息. 在正向索引中, 通过文档ID可以迅速找到文档中的所有单词及其位置.</p><p>正向索引的示例:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">文档1: [&quot;Elasticsearch&quot;, 位置1; &quot;is&quot;, 位置2; &quot;a&quot;, 位置3; …]</span><br><span class="line">文档2: [&quot;Elasticsearch&quot;, 位置1; &quot;allows&quot;, 位置2; &quot;you&quot;, 位置3; …]</span><br></pre></td></tr></table></figure><p><strong>倒排索引:</strong></p><p>它基于单词(term)建立索引, 而不是基于文档. 这意味着, 对于文档中的每个单词, 倒排索引都会记录哪些文档包含该单词以及该单词在文档中的位置信息(通常是词频和位置).</p><p>在 ES 中内置了很多的分词器, 在保存数据后, 会对数据进行分析, 生成词典, 每个单词会指向一个或多个倒排列表</p><p><strong>倒排索引的结构:</strong></p><ul><li>词典(Term Dictionary): 包含所有单词的列表, 每个单词指向一个或多个倒排列表.</li><li>倒排列表(Posting List): 对于每个单词, 包含一个列表, 其中记录了包含该单词的文档ID和该单词在文档中的位置信息.</li></ul><p>如下有两个文档:<br>文档1: “Elasticsearch is a powerful search engine.”<br>文档2: “Elasticsearch allows you to store, search, and analyze data efficiently.”</p><p>ES 会构建一个词典, 包括了上述所有的单词.<br>每个单词会指向一个或多个倒排列表.</p><p> <code>Elasticsearch: [文档1的ID, 位置1; 文档2的ID, 位置1]</code></p><p>Lucene 全文索引的核心是基于倒排索引实现的快速索引机制.</p><blockquote><p><a href="https://zq99299.github.io/note-book/elasticsearch-core/">https://zq99299.github.io/note-book/elasticsearch-core/</a><br><a href="https://cloud.tencent.com/developer/article/2393710">https://cloud.tencent.com/developer/article/2393710</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ES-是什么、干什么用的&quot;&gt;&lt;a href=&quot;#ES-是什么、干什么用的&quot; class=&quot;headerlink&quot; title=&quot;ES 是什么、干什么用的&quot;&gt;&lt;/a&gt;ES 是什么、干什么用的&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;分布式的搜索引擎和数据分析引擎&lt;ol&gt;
&lt;li&gt;</summary>
      
    
    
    
    <category term="大数据" scheme="https://champion-yang.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    <category term="存储" scheme="https://champion-yang.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%AD%98%E5%82%A8/"/>
    
    
    <category term="Elasticsearch" scheme="https://champion-yang.github.io/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>kafka 保证数据一致性</title>
    <link href="https://champion-yang.github.io/2024/07/09/02_kafka/2027-07-09kafka05-%E5%B9%82%E7%AD%89/"/>
    <id>https://champion-yang.github.io/2024/07/09/02_kafka/2027-07-09kafka05-%E5%B9%82%E7%AD%89/</id>
    <published>2024-07-09T08:57:15.000Z</published>
    <updated>2024-07-09T09:53:03.623Z</updated>
    
    <content type="html"><![CDATA[<h2 id="消息系统语义概述-Overview-of-messaging-system-semantics"><a href="#消息系统语义概述-Overview-of-messaging-system-semantics" class="headerlink" title="消息系统语义概述(Overview of messaging system semantics)"></a>消息系统语义概述(Overview of messaging system semantics)</h2><p>在一个分布式发布订阅消息系统中, 组成系统的计算机总会由于各自的故障而不能工作. 在Kafka中, 一个单独的broker, 可能会在生产者发送消息到一个topic的时候宕机, 或者出现网络故障, 从而导致生产者发送消息失败. 根据生产者如何处理这样的失败, 产生了不同的语义:</p><ul><li><strong>至少一次语义(At least once semantics)</strong>: 如果生产者收到了Kafka broker的确认(acknowledgement, ack), 并且生产者的acks配置项设置为all(或-1), 这就意味着消息已经被精确一次写入Kafka topic了. 然而, 如果生产者接收ack超时或者收到了错误, 它就会认为消息没有写入Kafka topic而尝试重新发送消息. 如果broker恰好在消息已经成功写入Kafka topic后, 发送ack前, 出了故障, 生产者的重试机制就会导致这条消息被写入Kafka两次, 从而导致同样的消息会被消费者消费不止一次. 每个人都喜欢一个兴高采烈的给予者, 但是这种方式会导致重复的工作和错误的结果.</li><li><strong>至多一次语义(At most once semantics)</strong>: 如果生产者在ack超时或者返回错误的时候不重试发送消息, 那么消息有可能最终并没有写入Kafka topic中, 因此也就不会被消费者消费到. 但是为了避免重复处理的可能性, 我们接受有些消息可能被遗漏处理.</li><li><strong>精确一次语义(Exactly once semantics)</strong>: 即使生产者重试发送消息, 也只会让消息被发送给消费者一次. 精确一次语义是最令人满意的保证, 但也是最难理解的. 因为它需要消息系统本身和生产消息的应用程序还有消费消息的应用程序一起合作. 比如, 在成功消费一条消息后, 你又把消费的offset重置到之前的某个offset位置, 那么你将收到从那个offset到最新的offset之间的所有消息. 这解释了为什么消息系统和客户端程序必须合作来保证精确一次语义.</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>将服务器的ACK级别设置为-1, 可以保证Producer到Server之间不会丢失数据, 即At Least Once语义.<br>相对的, 将服务器ACK级别设置为0, 可以保证生产者每条消息只会被发送一次, 即At Most Once语义.</p><p>At Least Once可以保证数据不丢失, 但是不能保证数据不重复;<br>相对的, At Least Once可以保证数据不重复, 但是不能保证数据不丢失.</p><p>但是, 对于一些非常重要的信息, 比如说交易数据, 下游数据消费者要求数据既不重复也不丢失, 即Exactly Once语义.<strong>在0.11版本以前的Kafka, 对此是无能为力的, 只能保证数据不丢失</strong>, 再在下游消费者对数据做全局去重. 对于多个下游应用的情况, 每个都需要单独做全局去重, 这就对性能造成了很大影响.</p><p>0.11版本的Kafka, 引入了一项重大特性:<strong>幂等性</strong>.</p><p>开启幂等性 <code>enable.idempotence=true</code> .</p><p>所谓的幂等性就是指Producer不论向Server发送多少次重复数据, Server端都只会持久化一条. 幂等性结合At Least Once语义, 就构成了Kafka的Exactly Once语义. 即:</p><p> <code>At Least Once + 幂等性 = Exactly Once</code></p><p>Kafka的幂等性实现其实就是将原来下游需要做的去重放在了数据上游. 开启幂等性的Producer在初始化的时候会被分配一个PID, 发往同一Partition的消息会附带Sequence Number. 而Broker端会对<br>&lt;PID, Partition, SeqNumber&gt;做缓存, 当具有相同主键的消息提交时, Broker只会持久化一条.</p><p>但是PID重启就会变化, 同时不同的Partition也具有不同主键, 所以幂等性无法保证跨分区跨会话的 Exactly Once.</p><p>所以0.11版本的Kafka引入了事务的概念</p><p><strong>事务: 跨partition的原子性写操作</strong><br>Kafka现在支持使用新事务API原子性的对跨partition进行写操作, 该API允许producer发送批量消息到多个partition. 该功能同样支持在同一个事务中提交消费者offsets, 因此真正意义上实现了end-to-end的exactly-once delivery语义.</p><h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><blockquote><p><a href="https://www.cnblogs.com/luxiaoxun/p/13048474.html">https://www.cnblogs.com/luxiaoxun/p/13048474.html</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;消息系统语义概述-Overview-of-messaging-system-semantics&quot;&gt;&lt;a href=&quot;#消息系统语义概述-Overview-of-messaging-system-semantics&quot; class=&quot;headerlink&quot; title</summary>
      
    
    
    
    <category term="技术" scheme="https://champion-yang.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
    <category term="Kafka" scheme="https://champion-yang.github.io/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>kafka的消费分区分配策略</title>
    <link href="https://champion-yang.github.io/2024/07/09/02_kafka/2027-07-09kafka04-kafka%E7%9A%84%E6%B6%88%E8%B4%B9%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5/"/>
    <id>https://champion-yang.github.io/2024/07/09/02_kafka/2027-07-09kafka04-kafka%E7%9A%84%E6%B6%88%E8%B4%B9%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5/</id>
    <published>2024-07-09T08:33:19.000Z</published>
    <updated>2024-07-09T08:40:42.207Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>这将是一篇比较无聊的文章</p></blockquote><p>一个consumer group中有多个consumer, 一个topic有多个partition, 所以必然会涉及到partition的分配问题, 即确定那个partition由哪个consumer来消费 Kafka有三种分配策略, 一是RoundRobin, 一是Range. 高版本还有一个StickyAssignor策略 将分区的所有权从一个消费者移到另一个消费者称为重新平衡(rebalance). 当以下事件发生时, Kafka 将会进行一次分区分配:</p><ul><li>同一个 Consumer Group 内新增消费者.</li><li>消费者离开当前所属的Consumer Group, 包括shuts down或crashes.</li></ul><h2 id="Range分区分配策略"><a href="#Range分区分配策略" class="headerlink" title="Range分区分配策略"></a>Range分区分配策略</h2><p>Range是对每个Topic而言的(即一个Topic一个Topic分), 首先对同一个Topic里面的分区按照序号进行排序, 并对消费者按照字母顺序进行排序. 然后用Partitions分区的个数除以消费者线程的总数来决定每个消费者线程消费几个分区. 如果除不尽, 那么前面几个消费者线程将会多消费一个分区. 假设n&#x3D;分区数&#x2F;消费者数量, m&#x3D;分区数%消费者数量, 那么前m个消费者每个分配n+1个分区, 后面的(消费者数<br>量-m)个消费者每个分配n个分区. 假如有10个分区, 3个消费者线程, 把分区按照序号排列<br>0, 1, 2, 3, 4, 5, 6, 7, 8, 9<br>消费者线程为<br>C1-0, C2-0, C2-1<br>那么用partition数除以消费者线程的总数来决定每个消费者线程消费几个partition, 如果除不尽, 前面几个消费者将会多消费一个分区. 在我们的例子里面, 我们有10个分区, 3个消费者线程, 10&#x2F;3 &#x3D; 3, 而且除不尽, 那么消费者线程C1-0将会多消费一个分区, 所以最后分区分配的结果看起来是这样的:<br>C1-0:0, 1, 2, 3<br>C2-0:4, 5, 6<br>C2-1:7, 8, 9<br>如果有11个分区将会是:<br>C1-0:0, 1, 2, 3<br>C2-0:4, 5, 6, 7<br>C2-1:8, 9, 10<br>假如我们有两个主题T1, T2, 分别有10个分区, 最后的分配结果将会是这样:<br>C1-0: T1(0, 1, 2, 3) T2(0, 1, 2, 3)<br>C2-0: T1(4, 5, 6) T2(4, 5, 6)<br>C2-1: T1(7, 8, 9) T2(7, 8, 9)</p><h2 id="RoundRobinAssignor分区分配策略"><a href="#RoundRobinAssignor分区分配策略" class="headerlink" title="RoundRobinAssignor分区分配策略"></a>RoundRobinAssignor分区分配策略</h2><p>RoundRobinAssignor策略的原理是将消费组内所有消费者以及消费者所订阅的所有topic的partition按照字典序排序, 然后通过轮询方式逐个将分区以此分配给每个消费者. 使用RoundRobin策略有两个前提条件必须满足:</p><ul><li>同一个消费者组里面的所有消费者的num.streams(消费者消费线程数)必须相等; </li><li>每个消费者订阅的主题必须相同.</li></ul><p>加入按照 hashCode 排序完的topic-partitions组依次为<br>T1-5, T1-3, T1-0, T1-8, T1-2, T1-1, T1-4, T1-7, T1-6, T1-9<br>我们的消费者线程排序为<br>C1-0, C1-1, C2-0, C2-1<br>最后分区分配的结果为:<br>C1-0 将消费 T1-5, T1-2, T1-6 分区<br>C1-1 将消费 T1-3, T1-1, T1-9 分区<br>C2-0 将消费 T1-0, T1-4 分区<br>C2-1 将消费 T1-8, T1-7 分区</p><h2 id="StickyAssignor分区分配策略"><a href="#StickyAssignor分区分配策略" class="headerlink" title="StickyAssignor分区分配策略"></a>StickyAssignor分区分配策略</h2><p>Kafka从0.11.x版本开始引入这种分配策略, 它主要有两个目的:<br>分区的分配要尽可能的均匀, 分配给消费者者的主题分区数最多相差一个分区的分配尽可能的与上次分配的保持相同.</p><p>当两者发生冲突时, 第一个目标优先于第二个目标. 鉴于这两个目的, StickyAssignor策略的具体实现要比RangeAssignor和RoundRobinAssignor这两种分配策略要复杂很多.</p><p>假设消费组内有3个消费者<br>C0、C1、C2<br>它们都订阅了4个主题:<br>t0、t1、t2、t3<br>并且每个主题有2个分区, 也就是说整个消费组订阅了<br>t0p0、t0p1、t1p0、t1p1、t2p0、t2p1、t3p0、t3p1这8个分区<br>最终的分配结果如下:<br>消费者C0:t0p0、t1p1、t3p0<br>消费者C1:t0p1、t2p0、t3p1<br>消费者C2:t1p0、t2p1<br>这样初看上去似乎与采用RoundRobinAssignor策略所分配的结果相同<br>此时假设消费者C1脱离了消费组, 那么消费组就会执行再平衡操作, 进而消费分区会重新分配. 如果采<br>用RoundRobinAssignor策略, 那么此时的分配结果如下:<br>消费者C0:t0p0、t1p0、t2p0、t3p0<br>消费者C2:t0p1、t1p1、t2p1、t3p1<br>如分配结果所示, RoundRobinAssignor策略会按照消费者C0和C2进行重新轮询分配. 而如果此时使用<br>的是StickyAssignor策略, 那么分配结果为:<br>消费者C0:t0p0、t1p1、t3p0、t2p0<br>消费者C2:t1p0、t2p1、t0p1、t3p1<br>可以看到分配结果中保留了上一次分配中对于消费者C0和C2的所有分配结果, 并将原来消费者C1的”负担”分配给了剩余的两个消费者C0和C2, 最终C0和C2的分配还保持了均衡.<br>如果发生分区重分配, 那么对于同一个分区而言有可能之前的消费者和新指派的消费者不是同一个, 对于之前消费者进行到一半的处理还要在新指派的消费者中再次复现一遍, 这显然很浪费系统资源.<br>StickyAssignor策略如同其名称中的”sticky”一样, 让分配策略具备一定的”粘性”, 尽可能地让前后两次分配相同, 进而减少系统资源的损耗以及其它异常情况的发生. 到目前为止所分析的都是消费者的订阅信息都是相同的情况, 我们来看一下订阅信息不同的情况下的处理.<br>举例, 同样消费组内有3个消费者:<br>C0、C1、C2<br>集群中有3个主题:<br>t0、t1、t2<br>这3个主题分别有<br>1、2、3个分区<br>也就是说集群中有<br>t0p0、t1p0、t1p1、t2p0、t2p1、t2p2这6个分区<br>消费者C0订阅了主题t0<br>消费者C1订阅了主题t0和t1<br>消费者C2订阅了主题t0、t1和t2<br>如果此时采用RoundRobinAssignor策略:<br>消费者C0:t0p0<br>消费者C1:t1p0<br>消费者C2:t1p1、t2p0、t2p1、t2p2<br>如果此时采用的是StickyAssignor策略:<br>消费者C0:t0p0<br>消费者C1:t1p0、t1p1<br>消费者C2:t2p0、t2p1、t2p2<br>此时消费者C0脱离了消费组, 那么RoundRobinAssignor策略的分配结果为:<br>消费者C1:t0p0、t1p1<br>消费者C2:t1p0、t2p0、t2p1、t2p2<br>StickyAssignor策略, 那么分配结果为:<br>消费者C1:t1p0、t1p1、t0p0<br>消费者C2:t2p0、t2p1、t2p2<br>可以看到StickyAssignor策略保留了消费者C1和C2中原有的5个分区的分配:<br>t1p0、t1p1、t2p0、t2p1、t2p2.<br>从结果上看StickyAssignor策略比另外两者分配策略而言显得更加的优异, 这个策略的代码实现也是异<br>常复杂.</p><h1 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h1><blockquote><p>公众号: 大数据左右手</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;这将是一篇比较无聊的文章&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;一个consumer group中有多个consumer, 一个topic有多个partition, 所以必然会涉及到partition的分配问题, 即确定那个partition由</summary>
      
    
    
    
    <category term="技术" scheme="https://champion-yang.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
    <category term="Kafka" scheme="https://champion-yang.github.io/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>kafka 常用命令</title>
    <link href="https://champion-yang.github.io/2024/07/08/02_kafka/2024-07-08-kafka03%E5%91%BD%E4%BB%A4/"/>
    <id>https://champion-yang.github.io/2024/07/08/02_kafka/2024-07-08-kafka03%E5%91%BD%E4%BB%A4/</id>
    <published>2024-07-08T06:33:09.000Z</published>
    <updated>2024-07-09T07:02:07.205Z</updated>
    
    <content type="html"><![CDATA[<p><strong>查看所有 topic</strong></p><ul><li><code>./kafka-topics.sh --zookeeper=10.5.208.13:2181 --list</code></li></ul><p><strong>创建topic——注意: 必须指定分区和副本, 否则会报错; 不同的版本需要指定的参数不同; Replication 不能超过 brokers 数量</strong></p><ul><li><code>bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 3 --topic testA</code></li><li><code>bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 3 --partitions 3 --topic testA</code></li></ul><p><strong>删除topic</strong></p><ul><li><code>./kafka-topics.sh --zookeeper=10.5.208.13:2181 --topic xxx --delete</code></li></ul><p><strong>查看topic属性</strong></p><ul><li><code>./kafka-topics.sh --describe --zookeeper=10.5.208.13:2181 --topic xxx</code></li></ul><p><strong>topic增加分区</strong></p><ul><li><code>./kafka-topics.sh --alter --zookeeper=10.5.208.13:2181 --topic xxx --partitions 10</code><blockquote><p>分区数增加到10个, 如果topic的分区增加, 则分区逻辑或消息顺序将受到影响, 会引起rebalance操作</p></blockquote></li></ul><p><strong>生产数据</strong></p><ul><li><code>./kafka-console-producer.sh --broker-list localhost:9092 --topic TCP_6666</code></li></ul><p><strong>消费数据</strong></p><ul><li><code>./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic first --from-beginning</code></li></ul><p><strong>重置偏移量</strong></p><ul><li><code>./kafka-consumer-groups.sh --bootstrap-server=10.5.208.13:9092 --execute --reset-offsets --topic=xxx --group=testPlatform-local-pha  --to-earliest</code></li></ul><p><strong>显示所有消费者</strong></p><ul><li><code>./kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list</code></li></ul><p><strong>查看Broker磁盘信息kafka-log-dirs.sh</strong></p><ul><li><p><code>/home/master/kafka/bin/kafka-log-dirs.sh --bootstrap-server localhost:9092 --describe --topic-list vuln</code></p></li><li><p><code>/home/master/kafka/bin/kafka-configs.sh --list --bootstrap-server localhost:9092</code></p></li><li><p><code>/home/master/kafka/bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic vuln</code></p></li></ul><p><strong>查询 kafka 消费者组的信息</strong></p><ul><li><p><code>kafka=/home/master/kafka/</code></p></li><li><p><code>$kafka/bin/kafka-consumer-groups.sh --bootstrap-server=localhost:9092 --describe --group &quot;groupName&quot;</code></p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;查看所有 topic&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;./kafka-topics.sh --zookeeper=10.5.208.13:2181 --list&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;创建topic</summary>
      
    
    
    
    <category term="技术" scheme="https://champion-yang.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
    <category term="Kafka" scheme="https://champion-yang.github.io/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>python虚拟环境</title>
    <link href="https://champion-yang.github.io/2024/07/08/python%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83/"/>
    <id>https://champion-yang.github.io/2024/07/08/python%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83/</id>
    <published>2024-07-08T06:14:22.000Z</published>
    <updated>2024-07-08T06:25:11.155Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>平常使用 anaconda 对开发环境做管理, 公司某天发了一条通知, 说 anaconda 未经授权不许使用, 存在 xxx 风险, 限令在一天内进行卸载. 在平常的一些 python 的项目中, anaconda 还是很方便的, 不同的项目管理不同的开发环境, 不过得合乎公司的规定, 所以只能通过其他的方式【命令】创建和管理虚拟环境了. 都是一些基础知识, 时间长没用, 做个记录.</p></blockquote><p><a href="https://www.anaconda.com/download/">anaconda</a></p><h1 id="使用-virtualenv-管理虚拟环境"><a href="#使用-virtualenv-管理虚拟环境" class="headerlink" title="使用 virtualenv 管理虚拟环境"></a>使用 virtualenv 管理虚拟环境</h1><p>由于项目需要, 需要同时具备 py2 和 py3, 所以在创建虚拟环境的时候需要指定 python 解释器</p><p>创建虚拟环境</p><p> <code>virtualenv env27 --python=python2.7</code></p><p>激活虚拟环境</p><ul><li>windows: <code>.\env27\Scripts\activate</code></li></ul><p>退出虚拟环境</p><ul><li>windows: <code>.\env27\Scripts\deactivate</code></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;平常使用 anaconda 对开发环境做管理, 公司某天发了一条通知, 说 anaconda 未经授权不许使用, 存在 xxx 风险, 限令在一天内进行卸载. 在平常的一些 python 的项目中, anaconda 还是很方便的, 不同的项目管理</summary>
      
    
    
    
    <category term="编程语言" scheme="https://champion-yang.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"/>
    
    
    <category term="Python" scheme="https://champion-yang.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>kafka踩过的坑</title>
    <link href="https://champion-yang.github.io/2024/07/05/02_kafka/2024-07-05-kafka02/"/>
    <id>https://champion-yang.github.io/2024/07/05/02_kafka/2024-07-05-kafka02/</id>
    <published>2024-07-05T08:48:17.000Z</published>
    <updated>2024-07-09T09:46:59.243Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h1><ol><li><a href="https://cloud.tencent.com/developer/article/1799294">我用kafka两年踩过的一些非比寻常的坑</a></li><li><a href="https://www.szzdzhp.com/"></a><a href="https://www.szzdzhp.com/">https://www.szzdzhp.com/</a></li></ol><h1 id="python-kafka"><a href="#python-kafka" class="headerlink" title="python-kafka"></a>python-kafka</h1><blockquote><p>在 python2 下测试 <code>kafka-python==1.4.7</code></p></blockquote><p>安装<br> <code>pip2 install kafka-python==1.4.7</code></p><h2 id="异常"><a href="#异常" class="headerlink" title="异常"></a>异常</h2><p><a href="https://blog.csdn.net/qq_16829085/article/details/108414433">使用 kafka-python 产生的错误</a></p><p> <code>ValueError: filedescriptor out of range in select()</code></p><p> <a href="https://blog.csdn.net/whatday/article/details/113771166">fd 超出 1024 导致的异常1</a><br> <a href="https://github.com/dpkp/kafka-python/issues/1952">fd 超出 1024 导致的异常2</a></p><p><img src="/../../images/kafka/01.png" alt="img"></p><h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><h3 id="SimplePorducer"><a href="#SimplePorducer" class="headerlink" title="SimplePorducer"></a>SimplePorducer</h3><blockquote><p>send_messages接收多个发送消息, 用create_message_set打包成一个messages列表, messages传给ProduceRequestPayload创建一个payloads对象, 用payload对应的broker对payloads分组, 遍历这个分组每个分组发送一次, 用ProduceRequest对payload创建request对象, 用BrokerConnection对象发送request对象, 发送时使用的socket连接, 发送后返回一个future对象, 再用select.select监听这些连接, 当文件描述符超过1024时报错就是这时候发生的.client的创建类为KafkaClient, 基础类为SimpleClent</p></blockquote><blockquote><p>问题, select.select监听文件描述符报错, 文件描述符报错实际是在SimpleClent._send_broker_aware_request中产生, 可能的话可以重写_send_broker_aware_request方法</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> kafka <span class="keyword">import</span> KafkaClient,SimpleProducer</span><br><span class="line">host = <span class="string">&#x27;10.8.100.7:9092&#x27;</span></span><br><span class="line">client = KafkaClient(host=host)</span><br><span class="line">producer = SimpleProducer(client=client)</span><br><span class="line">messages = [<span class="string">&#x27;messageA&#x27;</span>,<span class="string">&#x27;messageB&#x27;</span>]</span><br><span class="line">topic = <span class="string">&#x27;topic&#x27;</span></span><br><span class="line">producer.send_messages(topic,*messages)</span><br></pre></td></tr></table></figure><h3 id="KafkaProducer"><a href="#KafkaProducer" class="headerlink" title="KafkaProducer"></a>KafkaProducer</h3><blockquote><p>KafkaProducer通过send在代码逻辑上发送发送单条消息, 但是KafkaProducer实现了一个了一个线程, 通过send将消息发送到列表中, 在线程通过消费这个列表, 当消息满足batch_size个字符的数据的发送条件时, 会讲batch_size个字符的数据用socket发送给kafka, 发送完成会将连接放入_sending. 这个线程是一个循环调用run_once方法, 在run_once发送中调用发送逻辑, 发送完成后讲_sending中conn注册到kqueue中, 等待连接回调. 因为KafkaProducer使用的是kqueue, 所以不会碰到和SimpleProducer一样的问题.</p></blockquote><p>后线程的实现类是Sender, kafka连接类是BrokerConnection, kafka client类是client_async. KafkaClient, selector类是vendor&#x2F;selectors34.py. KqueueSelector</p><blockquote><p>问题:kafkaProducer当发送数据比较多时, 发送次数也会多, 当在django中请求比较少时, 发送到列表中数据也少, 发送一个请求发送到kafka中, 可能连续都完成了, </p></blockquote><p>发送很快, 当请求变多时, 发送到列表中的数据变的无序, 不一定属于那个哪个请求的哪一次kafka发送, 因此会导致请求的数据发送到kafka变慢.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> kafka <span class="keyword">import</span> KafkaProducer</span><br><span class="line">host = <span class="string">&#x27;10.8.100.7:9092&#x27;</span></span><br><span class="line">producer = KafkaProducer(bootstrap_servers=host)</span><br><span class="line">messages = [<span class="string">&#x27;messageA&#x27;</span>,<span class="string">&#x27;messageB&#x27;</span>]</span><br><span class="line">topic = <span class="string">&#x27;topic&#x27;</span></span><br><span class="line"><span class="keyword">for</span> message <span class="keyword">in</span> messages:</span><br><span class="line">    producer.send(topic,messages)</span><br></pre></td></tr></table></figure><h1 id="kafka-消费的坑"><a href="#kafka-消费的坑" class="headerlink" title="kafka 消费的坑"></a>kafka 消费的坑</h1><p><a href="https://juejin.cn/post/7314509615159885875">kafka积压类问题</a><a href="https://juejin.cn/post/7314509615159885875">https://juejin.cn/post/7314509615159885875</a><br><a href="https://www.cnblogs.com/even160941/p/17010989.html">kafka如何处理大量积压消息</a><a href="https://www.cnblogs.com/even160941/p/17010989.html">https://www.cnblogs.com/even160941/p/17010989.html</a></p><h2 id="数据积压问题"><a href="#数据积压问题" class="headerlink" title="数据积压问题"></a>数据积压问题</h2><p>在大数据的场景下使用 MQ 一定会遇到数据积压的问题</p><p>Kafka消息积压的问题, 核心原因是生产太快、消费太慢, 处理速度长期失衡, 从而导致消息积压(Lag)的场景, 积压到超过队列长度限制, 就会出现还未被消费的数据产生丢失的场景.</p><h3 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a>生产者</h3><p>生产者异常导致重复生产数据, 需要考虑代码健壮性;<br>服务器的ACK级别设置为-1, 即 <code>At Least Once</code> 可以保证数据不丢失, 但是不能保证数据不重复; </p><p>处理方式:</p><ol><li>幂等性 <strong>Exactly Once</strong>，数据不会重复生产【0.11版本的kafka才会有的特性】</li><li>优化生产逻辑，做好监控预警功能</li></ol><h3 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h3><p>消费者业务流程复杂, 消费速率远远小于生产速录, 产生消息积压; 涉及到 IO 的交互和网络的交互, 比如数据库SQL执行慢, 调用其他系统的API慢等<br>总结有两方面原因:</p><ul><li>消费能力不足: 消费的慢, 逻辑问题</li><li>数据处理&#x2F;拉取能力不足:(拉取数据&#x2F;处理时间 &lt; 生产速度)</li></ul><p>第一种处理方式:</p><ol><li>对partition扩容增加partition数量</li><li>将消费者代码修改为多线程并发消费</li><li>提高单条消息的处理速度, 如: 优化业务流程, 增加缓存, 去掉耗时操作</li></ol><p>第二种处理方式:</p><p>max.poll.records &#x3D; 20, 而 max.poll.interval.ms &#x3D; 1000, 也就是说consumer一次最多拉取 20 条消息, 两次拉取的最长时间间隔为 1 秒.<br>也就是说消费者拉取的20条消息必须在1秒内处理完成, 紧接着拉取下一批消息. 否则, 超过1秒后, Kafka broker会认为该消费者处理太缓慢而将他踢出消费组, 从而导致消费组rebalance.<br>根据Kafka机制, 消费组rebalance过程中是不会消费消息的, 所以看到ip是B和C轮流拉取消息, 又轮流被踢出消费组, 消费组循环进行rebalance, 消费就堆积了</p><p>处理方案: 消费者客户端减小 max.poll.records 或 增加 max.poll.interval.ms . RD 将 max.poll.records 设置为 1, 重启消费者后消费恢复</p><h2 id="重复消费问题"><a href="#重复消费问题" class="headerlink" title="重复消费问题"></a>重复消费问题</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;引用&quot;&gt;&lt;a href=&quot;#引用&quot; class=&quot;headerlink&quot; title=&quot;引用&quot;&gt;&lt;/a&gt;引用&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://cloud.tencent.com/developer/article/1799294&quot;&gt;我用</summary>
      
    
    
    
    <category term="大数据" scheme="https://champion-yang.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Kafka" scheme="https://champion-yang.github.io/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>kafka架构理解和基本概念</title>
    <link href="https://champion-yang.github.io/2024/07/05/02_kafka/2024-07-05-kafka01/"/>
    <id>https://champion-yang.github.io/2024/07/05/02_kafka/2024-07-05-kafka01/</id>
    <published>2024-07-05T08:26:02.000Z</published>
    <updated>2024-07-09T08:54:49.049Z</updated>
    
    <content type="html"><![CDATA[<h1 id="为什么要用消息队列"><a href="#为什么要用消息队列" class="headerlink" title="为什么要用消息队列"></a>为什么要用消息队列</h1><ol><li>解耦<br>允许你独立的扩展或修改两边的处理过程, 只要确保它们遵守同样的接口约束.</li><li>可恢复性<br>系统的一部分组件失效时, 不会影响到整个系统. 消息队列降低了进程间的耦合度, 所以即使一个处理<br>消息的进程挂掉, 加入队列中的消息仍然可以在系统恢复后被处理.</li><li>缓冲<br>有助于控制和优化数据流经过系统的速度, 解决生产消息和消费消息的处理速度不一致的情况.</li><li>灵活性与峰值处理能力<br>在访问量剧增的情况下, 应用仍然需要继续发挥作用, 但是这样的突发流量并不常见. 如果为以能处理<br>这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费. 使用消息队列能够使关键组件顶住突发的<br>访问压力, 而不会因为突发的超负荷的请求而完全崩溃.</li><li>异步通信<br>很多时候, 用户不想也不需要立即处理消息. 消息队列提供了异步处理机制, 允许用户把一个消息放入<br>队列, 但并不立即处理它. 想向队列中放入多少消息就放多少, 然后在需要的时候再去处理它们.</li></ol><h1 id="Kafka适合以下应用场景"><a href="#Kafka适合以下应用场景" class="headerlink" title="Kafka适合以下应用场景"></a>Kafka适合以下应用场景</h1><ol><li>日志收集：一个公司可以用Kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放<br>给各种consumer.</li><li>消息系统：解耦生产者和消费者、缓存消息等。</li><li>用户活动跟踪：kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击<br>等活动, 这些活动信息被各个服务器发布到kafka的topic中, 然后消费者通过订阅这些topic来做实<br>时的监控分析, 亦可保存到数据库.</li><li>运营指标：kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作<br>的集中反馈, 比如报警和报告; </li><li>流式处理：比如spark和flink。</li></ol><h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><ol><li>Producer ：消息生产者，就是向kafka broker发消息的客户端。</li><li>Consumer ：消息消费者，向kafka broker取消息的客户端。</li><li>Consumer Group （CG）：消费者组，由多个consumer组成。消费者组内每个消费者负责消费不同分区的数据, 一个分区只能由一个组内消费者消费; 消费者组之间互不影响. 所有的消费者都属于某个消费者组, 即<strong>消费者组是逻辑上的一个订阅者</strong>.</li><li>Broker ：一台kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic.</li><li>Topic ：可以理解为一个队列，生产者和消费者面向的都是一个topic。</li><li>Partition：为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，一个topic可以分为多个partition, <strong>每个partition是一个有序的队列</strong>.</li><li>Replica：副本，为保证集群中的某个节点发生故障时，该节点上的partition数据不丢失，且kafka仍然能够继续工作, kafka提供了副本机制, 一个topic的每个分区都有若干个副本, 一个leader和若干个follower.</li><li>leader：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是leader.</li><li>follower：每个分区多个副本中的“从”，实时从leader中同步数据，保持和leader数据的同步。leader发生故障时, 某个follower会成为新的follower.</li></ol><h1 id="kafka为什么要分区"><a href="#kafka为什么要分区" class="headerlink" title="kafka为什么要分区"></a>kafka为什么要分区</h1><ol><li>方便在集群中扩展，每个Partition可以通过调整以适应它所在的机器，而一个topic又可以有多个<br>Partition组成, 因此整个集群就可以适应任意大小的数据了.</li><li>可以提高并发，因为可以以Partition为单位读写。</li></ol><h1 id="Kafka生产者分区策略"><a href="#Kafka生产者分区策略" class="headerlink" title="Kafka生产者分区策略"></a>Kafka生产者分区策略</h1><ol><li>指明 partition 的情况下，直接将指明的值直接作为partiton值。</li><li>没有指明partition值但有key的情况下，将key的hash值与topic的partition数进行取余得到<br>partition值.</li><li>既没有partition值又没有key值的情况下，第一次调用时随机生成一个整数(后面每次调用在这个<br>整数上自增), 将这个值与topic可用的partition总数取余得到partition值, 也就是常说的round-robin算法.</li></ol><h1 id="kafka的数据可靠性怎么保证"><a href="#kafka的数据可靠性怎么保证" class="headerlink" title="kafka的数据可靠性怎么保证"></a>kafka的数据可靠性怎么保证</h1><p>为保证producer发送的数据, 能可靠的发送到指定的topic, topic的每个partition收到producer发送的<br>数据后, 都需要向producer发送ack(acknowledgement确认收到), 如果producer收到ack, 就会进<br>行下一轮的发送, 否则重新发送数据. 所以引出ack机制.</p><h1 id="数据重复和丢失问题"><a href="#数据重复和丢失问题" class="headerlink" title="数据重复和丢失问题"></a>数据重复和丢失问题</h1><p>Kafka为用户提供了三种可靠性级别, 用户根据对可靠性和延迟的要求进行权衡, 选择以下的配置.</p><p>acks参数配置:</p><ul><li>0:producer不等待broker的ack, 这一操作提供了一个最低的延迟, broker一接收到还没有写入磁盘就已经返回, 当broker故障时有可能丢失数据.</li><li>1:producer等待broker的ack, partition的leader落盘成功后返回ack, 如果在follower同步成功之前leader故障, 那么将会丢失数据.</li><li>-1(all):producer等待broker的ack, partition的leader和follower全部落盘成功后才返回ack.<br>但是如果在follower同步完成后, broker发送ack之前, leader发生故障, 那么会造成数据重复.</li></ul><h1 id="Kafka消费能力不足怎么处理"><a href="#Kafka消费能力不足怎么处理" class="headerlink" title="Kafka消费能力不足怎么处理"></a>Kafka消费能力不足怎么处理</h1><ol><li>如果是Kafka消费能力不足，则可以考虑增加Topic的分区数，并且同时提升消费组的消费者数量，<br>消费者数&#x3D;分区数.(两者缺一不可)</li><li>如果是下游的数据处理不及时：提高每批次拉取的数量。批次拉取数据过少（拉取数据&#x2F;处理时间&lt;<br>生产速度), 使处理的数据小于生产的数据, 也会造成数据积压.</li></ol><h1 id="Kafka中的数据是有序的吗"><a href="#Kafka中的数据是有序的吗" class="headerlink" title="Kafka中的数据是有序的吗"></a>Kafka中的数据是有序的吗</h1><p>单分区内有序.<br>多分区, 分区与分区间无序.</p><h1 id="Kafka可以按照时间消费数据吗"><a href="#Kafka可以按照时间消费数据吗" class="headerlink" title="Kafka可以按照时间消费数据吗"></a>Kafka可以按照时间消费数据吗</h1><p>可以, 提供的API方法:<br>KafkaUtil.fetchOffsetsWithTimestamp(topic, sTime, kafkaProp)</p><h1 id="Kafka单条日志传输大小"><a href="#Kafka单条日志传输大小" class="headerlink" title="Kafka单条日志传输大小"></a>Kafka单条日志传输大小</h1><p>kafka对于消息体的大小默认为单条最大值是1M但是在我们应用场景中, 常常会出现一条消息大于1M,<br>如果不对kafka进行配置. 则会出现生产者无法将消息推送到kafka或消费者无法去消费kafka里面的数<br>据, 这时我们就要对kafka进行以下配置:server.properties</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">replica.fetch.max.bytes: 1048576 # broker可复制的消息的最大字节数, 默认为1M</span><br><span class="line">message.max.bytes: 1000012 # kafka 会接收单个消息size的最大限制， 默认为1M左右</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">注意 message.max.bytes必须小于等于replica.fetch.max.bytes，否则就会导致replica之间数据同步失败</span></span><br></pre></td></tr></table></figure><h1 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h1><ol><li><a href="https://kafka1x.apachecn.org/">kafka官方中文文档</a> </li><li>公众号: 大数据左右手</li><li><a href="https://cloud.tencent.com/developer/article/1991788">超详细的Kafka教程-从部署到开发到原理都有讲解</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;为什么要用消息队列&quot;&gt;&lt;a href=&quot;#为什么要用消息队列&quot; class=&quot;headerlink&quot; title=&quot;为什么要用消息队列&quot;&gt;&lt;/a&gt;为什么要用消息队列&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;解耦&lt;br&gt;允许你独立的扩展或修改两边的处理过程, 只要确保它们遵守同样</summary>
      
    
    
    
    <category term="大数据" scheme="https://champion-yang.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Kafka" scheme="https://champion-yang.github.io/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>2024-07-04-pandas03</title>
    <link href="https://champion-yang.github.io/2024/07/04/01_pandas/2024-07-04-pandas03/"/>
    <id>https://champion-yang.github.io/2024/07/04/01_pandas/2024-07-04-pandas03/</id>
    <published>2024-07-04T07:33:47.000Z</published>
    <updated>2024-07-04T08:41:53.015Z</updated>
    
    
    
    
    <category term="数据科学" scheme="https://champion-yang.github.io/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
    <category term="数据处理" scheme="https://champion-yang.github.io/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    
    
  </entry>
  
  <entry>
    <title>pandas 处理 excel 表格合并操作</title>
    <link href="https://champion-yang.github.io/2024/07/04/01_pandas/2024-07-04-pandas02/"/>
    <id>https://champion-yang.github.io/2024/07/04/01_pandas/2024-07-04-pandas02/</id>
    <published>2024-07-04T07:29:31.000Z</published>
    <updated>2024-07-23T06:32:44.542Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要记录利用 pandas 操作 excel 中, 表格合并操作的代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> openpyxl <span class="keyword">import</span> load_workbook</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> openpyxl</span><br><span class="line"><span class="keyword">from</span> openpyxl.styles <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> date</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">解析大表，输出 excel, 每一列生成一份 excel 文件</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义合并单元格的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Merge_cells</span>(<span class="params">ws, target_list, start_row, col, end_row=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    ws: 是需要操作的工作表</span></span><br><span class="line"><span class="string">    target_list: 是目标列表，即含有重复数据的列表</span></span><br><span class="line"><span class="string">    start_row: 是开始行，即工作表中开始比对数据的行（需要将标题除开）</span></span><br><span class="line"><span class="string">    col: 是需要处理数据的列</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    start = <span class="number">0</span>  <span class="comment"># 开始行计数，初试值为0，对应列表中的第1个元素的位置0</span></span><br><span class="line">    end = <span class="number">0</span>  <span class="comment"># 结束行计数，初试值为0，对应列表中的第1个元素的位置0</span></span><br><span class="line">    reference = target_list[<span class="number">0</span>]  <span class="comment"># 设定基准，以列表中的第一个字符串开始</span></span><br><span class="line">    <span class="keyword">if</span> end_row:</span><br><span class="line">        target_list = target_list[start_row - <span class="number">1</span>:end_row]</span><br><span class="line">        reference = target_list[<span class="number">0</span>]  <span class="comment"># 设定基准，以列表中的第一个字符串开始</span></span><br><span class="line">        <span class="comment"># print(&quot;target_list&quot;, target_list)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># print(&quot;reference&quot;, reference)</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(target_list)):  <span class="comment"># 遍历列表</span></span><br><span class="line">            <span class="keyword">if</span> target_list[i] != reference:  <span class="comment"># 开始比对，如果内容不同执行如下</span></span><br><span class="line">                reference = target_list[i]  <span class="comment"># 基准变成列表中下一个字符串</span></span><br><span class="line">                end = i - <span class="number">1</span>  <span class="comment"># 列计数器</span></span><br><span class="line">                ws.merge_cells(col + <span class="built_in">str</span>(start + start_row) + <span class="string">&quot;:&quot;</span> + col + <span class="built_in">str</span>(end + start_row))</span><br><span class="line">                start = end + <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> i == <span class="built_in">len</span>(target_list) - <span class="number">1</span>:  <span class="comment"># 遍历到最后一行，按如下操作</span></span><br><span class="line">                end = i</span><br><span class="line">                ws.merge_cells(col + <span class="built_in">str</span>(start + start_row) + <span class="string">&quot;:&quot;</span> + col + <span class="built_in">str</span>(end + start_row))</span><br><span class="line">                reference = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(target_list)):  <span class="comment"># 遍历列表</span></span><br><span class="line">            <span class="keyword">if</span> target_list[i] != reference:  <span class="comment"># 开始比对，如果内容不同执行如下</span></span><br><span class="line">                reference = target_list[i]  <span class="comment"># 基准变成列表中下一个字符串</span></span><br><span class="line">                end = i - <span class="number">1</span>  <span class="comment"># 列计数器</span></span><br><span class="line">                ws.merge_cells(col + <span class="built_in">str</span>(start + start_row) + <span class="string">&quot;:&quot;</span> + col + <span class="built_in">str</span>(end + start_row))</span><br><span class="line">                start = end + <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> i == <span class="built_in">len</span>(target_list) - <span class="number">1</span>:  <span class="comment"># 遍历到最后一行，按如下操作</span></span><br><span class="line">                end = i</span><br><span class="line">                ws.merge_cells(col + <span class="built_in">str</span>(start + start_row) + <span class="string">&quot;:&quot;</span> + col + <span class="built_in">str</span>(end + start_row))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取Excel表格中的数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置边框&#123;&#x27;medium&#x27; 中粗 &#x27;thin&#x27;  细  &#x27;thick&#x27;  粗  &#x27;dashed&#x27;  虚线  &#x27;dotted&#x27;  点线&#125;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">format_border_cell</span>(<span class="params">ws, row_index, col_index</span>):</span><br><span class="line">    ws.cell(row_index, col_index).border = Border(top=Side(border_style=<span class="string">&#x27;thin&#x27;</span>, color=<span class="string">&#x27;FF000000&#x27;</span>),</span><br><span class="line">                                                  right=Side(border_style=<span class="string">&#x27;thin&#x27;</span>, color=<span class="string">&#x27;FF000000&#x27;</span>),</span><br><span class="line">                                                  bottom=Side(border_style=<span class="string">&#x27;thin&#x27;</span>, color=<span class="string">&#x27;FF000000&#x27;</span>),</span><br><span class="line">                                                  left=Side(border_style=<span class="string">&#x27;thin&#x27;</span>, color=<span class="string">&#x27;FF000000&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_schema</span>(<span class="params">file_path</span>):</span><br><span class="line">    wb = load_workbook(file_path)</span><br><span class="line">    sheet_names = wb.get_sheet_names()</span><br><span class="line">    <span class="keyword">for</span> sheet_name <span class="keyword">in</span> sheet_names:  <span class="comment"># 遍历每个工作表，抓取数据，并根据要求合并单元格</span></span><br><span class="line">        ws = wb[sheet_name]</span><br><span class="line">        target_list = []  <span class="comment"># 考核类型</span></span><br><span class="line">        customer_list = []</span><br><span class="line">        _lst_2 = []</span><br><span class="line">        _lst_3 = []</span><br><span class="line">        _lst_4 = []</span><br><span class="line">        _lst_5 = []</span><br><span class="line">        _lst_6 = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">66</span>):</span><br><span class="line">            customer = ws[<span class="string">&#x27;A&#x27;</span> + <span class="built_in">str</span>(row)].value</span><br><span class="line">            customer_list.append(customer)</span><br><span class="line">            _2 = ws[<span class="string">&#x27;B&#x27;</span> + <span class="built_in">str</span>(row)].value</span><br><span class="line">            _lst_2.append(_2)</span><br><span class="line">            _3 = ws[<span class="string">&#x27;C&#x27;</span> + <span class="built_in">str</span>(row)].value</span><br><span class="line">            _lst_3.append(_3)</span><br><span class="line">            _4 = ws[<span class="string">&#x27;D&#x27;</span> + <span class="built_in">str</span>(row)].value</span><br><span class="line">            _lst_4.append(_4)</span><br><span class="line">            _5 = ws[<span class="string">&#x27;E&#x27;</span> + <span class="built_in">str</span>(row)].value</span><br><span class="line">            _lst_5.append(_5)</span><br><span class="line">            _6 = ws[<span class="string">&#x27;F&#x27;</span> + <span class="built_in">str</span>(row)].value</span><br><span class="line">            _lst_6.append(_6)</span><br><span class="line"></span><br><span class="line">        start_row = <span class="number">1</span>  <span class="comment"># 开始行是第六行</span></span><br><span class="line">        Merge_cells(ws, customer_list, start_row, <span class="string">&quot;A&quot;</span>)</span><br><span class="line">        Merge_cells(ws, _lst_2, start_row, <span class="string">&quot;B&quot;</span>)</span><br><span class="line">        Merge_cells(ws, _lst_3, start_row, <span class="string">&quot;C&quot;</span>)</span><br><span class="line">        <span class="comment"># Merge_cells(ws, _lst_4, start_row, &quot;D&quot;)</span></span><br><span class="line">        Merge_cells(ws, _lst_4, <span class="number">2</span>, <span class="string">&quot;D&quot;</span>, end_row=<span class="number">13</span>)</span><br><span class="line">        Merge_cells(ws, _lst_4, <span class="number">14</span>, <span class="string">&quot;D&quot;</span>, end_row=<span class="number">24</span>)</span><br><span class="line">        Merge_cells(ws, _lst_4, <span class="number">25</span>, <span class="string">&quot;D&quot;</span>, end_row=<span class="number">27</span>)</span><br><span class="line">        Merge_cells(ws, _lst_4, <span class="number">28</span>, <span class="string">&quot;D&quot;</span>, end_row=<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Merge_cells(ws, _lst_4, 28, &quot;D&quot;, end_row=33)</span></span><br><span class="line">        Merge_cells(ws, _lst_4, <span class="number">33</span>, <span class="string">&quot;D&quot;</span>, end_row=<span class="number">34</span>)</span><br><span class="line">        Merge_cells(ws, _lst_4, <span class="number">35</span>, <span class="string">&quot;D&quot;</span>, end_row=<span class="number">38</span>)</span><br><span class="line">        Merge_cells(ws, _lst_4, <span class="number">39</span>, <span class="string">&quot;D&quot;</span>, end_row=<span class="number">41</span>)</span><br><span class="line">        Merge_cells(ws, _lst_4, <span class="number">42</span>, <span class="string">&quot;D&quot;</span>, end_row=<span class="number">49</span>)</span><br><span class="line">        Merge_cells(ws, _lst_4, <span class="number">50</span>, <span class="string">&quot;D&quot;</span>, end_row=<span class="number">56</span>)</span><br><span class="line">        Merge_cells(ws, _lst_4, <span class="number">57</span>, <span class="string">&quot;D&quot;</span>, end_row=<span class="number">65</span>)</span><br><span class="line"></span><br><span class="line">        Merge_cells(ws, _lst_5, start_row, <span class="string">&quot;E&quot;</span>)</span><br><span class="line">        Merge_cells(ws, _lst_6, start_row, <span class="string">&quot;F&quot;</span>)</span><br><span class="line">        alignment_center = Alignment(horizontal=<span class="string">&#x27;left&#x27;</span>, vertical=<span class="string">&#x27;center&#x27;</span>, wrapText=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建边框线对象</span></span><br><span class="line">        border = Border(top=Side(border_style=<span class="string">&#x27;thick&#x27;</span>, color=<span class="string">&#x27;FF000000&#x27;</span>),</span><br><span class="line">                        right=Side(border_style=<span class="string">&#x27;thick&#x27;</span>, color=<span class="string">&#x27;FF000000&#x27;</span>),</span><br><span class="line">                        bottom=Side(border_style=<span class="string">&#x27;thick&#x27;</span>, color=<span class="string">&#x27;FF000000&#x27;</span>),</span><br><span class="line">                        left=Side(border_style=<span class="string">&#x27;thick&#x27;</span>, color=<span class="string">&#x27;FF000000&#x27;</span>))</span><br><span class="line">        <span class="comment"># 指定区域单元格居中</span></span><br><span class="line">        ws_area = ws[<span class="string">&quot;A1:H65&quot;</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> ws_area:</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> i:</span><br><span class="line">                j.alignment = alignment_center</span><br><span class="line">                <span class="comment"># j.border = border</span></span><br><span class="line"></span><br><span class="line">        font1 = Font(name=<span class="string">&quot;黑体&quot;</span>)</span><br><span class="line">        font2 = Font(name=<span class="string">&quot;黑体&quot;</span>, bold=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 指定区域单元格字体</span></span><br><span class="line">        ws_area = ws[<span class="string">&quot;A1:H1&quot;</span>]</span><br><span class="line">        k = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> ws_area:</span><br><span class="line">            k = k + <span class="number">1</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> i:</span><br><span class="line">                <span class="keyword">if</span> (k == <span class="number">1</span>):</span><br><span class="line">                    j.font = font2</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    j.font = font1</span><br><span class="line">        ws.column_dimensions[<span class="string">&#x27;A&#x27;</span>].width = <span class="number">20.0</span></span><br><span class="line">        ws.column_dimensions[<span class="string">&#x27;B&#x27;</span>].width = <span class="number">20.0</span></span><br><span class="line">        ws.column_dimensions[<span class="string">&#x27;C&#x27;</span>].width = <span class="number">20.0</span></span><br><span class="line">        ws.column_dimensions[<span class="string">&#x27;D&#x27;</span>].width = <span class="number">20.0</span></span><br><span class="line">        ws.column_dimensions[<span class="string">&#x27;E&#x27;</span>].width = <span class="number">30.0</span></span><br><span class="line">        ws.column_dimensions[<span class="string">&#x27;F&#x27;</span>].width = <span class="number">30.0</span></span><br><span class="line">        ws.column_dimensions[<span class="string">&#x27;G&#x27;</span>].width = <span class="number">40.0</span></span><br><span class="line">        ws.column_dimensions[<span class="string">&#x27;H&#x27;</span>].width = <span class="number">30.0</span></span><br><span class="line"></span><br><span class="line">    wb.save(file_path)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">p1</span>):</span><br><span class="line">    <span class="comment"># 读取 Excel 文件</span></span><br><span class="line">    file_path = p1</span><br><span class="line">    df = pd.read_excel(file_path, engine=<span class="string">&#x27;openpyxl&#x27;</span>, sheet_name=<span class="string">&quot;xxx&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取所有列名</span></span><br><span class="line">    column_names_0_5 = df.columns[:<span class="number">7</span>]</span><br><span class="line">    column_names_6_ = df.columns[<span class="number">7</span>:]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 写入 excel</span></span><br><span class="line">    <span class="keyword">for</span> column_name <span class="keyword">in</span> column_names_6_:</span><br><span class="line">        <span class="comment"># 提取当前列的数据</span></span><br><span class="line">        column_name_lst = <span class="built_in">list</span>(column_names_0_5) + [<span class="built_in">str</span>(column_name)]</span><br><span class="line">        column_data = df[column_name_lst]</span><br><span class="line">        pd_column_data = column_data.ffill()</span><br><span class="line"></span><br><span class="line">        column_data_one = <span class="built_in">set</span>(df[<span class="built_in">str</span>(column_name)].values)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 在当前路径下创建文件夹</span></span><br><span class="line">        folder_name_lst = [<span class="string">&quot;&#123;&#125;\xxx路径\&#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">str</span>(date.today()), i) <span class="keyword">for</span> i <span class="keyword">in</span> [<span class="string">&quot;移动&quot;</span>,<span class="string">&quot;联通&quot;</span>,<span class="string">&quot;电信&quot;</span>]]</span><br><span class="line">        <span class="keyword">for</span> folder_name <span class="keyword">in</span> folder_name_lst:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(folder_name):</span><br><span class="line">                os.makedirs(folder_name)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="string">&quot;移动&quot;</span> <span class="keyword">in</span> column_name:</span><br><span class="line">            new_file_name = <span class="string">&quot;&#123;&#125;\xxx路径\&#123;&#125;\\&quot;</span>.<span class="built_in">format</span>(<span class="built_in">str</span>(date.today()), <span class="string">&quot;移动&quot;</span>) + column_name + <span class="string">&quot;.xlsx&quot;</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="string">&quot;联通&quot;</span> <span class="keyword">in</span> column_name:</span><br><span class="line">            new_file_name = <span class="string">&quot;&#123;&#125;\xxx路径\&#123;&#125;\\&quot;</span>.<span class="built_in">format</span>(<span class="built_in">str</span>(date.today()), <span class="string">&quot;联通&quot;</span>) + column_name + <span class="string">&quot;.xlsx&quot;</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="string">&quot;电信&quot;</span> <span class="keyword">in</span> column_name:</span><br><span class="line">            new_file_name = <span class="string">&quot;&#123;&#125;\xxx路径\&#123;&#125;\\&quot;</span>.<span class="built_in">format</span>(<span class="built_in">str</span>(date.today()), <span class="string">&quot;电信&quot;</span>) + column_name + <span class="string">&quot;.xlsx&quot;</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> <span class="string">&quot;=================&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建新的 sheet，并将列名作为 sheet 名称</span></span><br><span class="line">        new_sheet_name = <span class="string">f&#x27;<span class="subst">&#123;column_name&#125;</span>&#x27;</span></span><br><span class="line">        pd_column_data.to_excel(new_file_name, sheet_name=new_sheet_name, index=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        set_schema(new_file_name)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    file_path = <span class="string">r&#x27;./文件.xlsx&quot;</span></span><br><span class="line"><span class="string">    main(file_path)</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本文主要记录利用 pandas 操作 excel 中, 表格合并操作的代码&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;</summary>
      
    
    
    
    <category term="数据科学" scheme="https://champion-yang.github.io/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
    <category term="数据处理" scheme="https://champion-yang.github.io/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    
    
    <category term="Pandas" scheme="https://champion-yang.github.io/tags/Pandas/"/>
    
  </entry>
  
  <entry>
    <title>研发工程视角下的数据分析(数据处理)</title>
    <link href="https://champion-yang.github.io/2024/07/04/01_pandas/2024-07-04-pandas01/"/>
    <id>https://champion-yang.github.io/2024/07/04/01_pandas/2024-07-04-pandas01/</id>
    <published>2024-07-04T06:06:55.000Z</published>
    <updated>2024-07-08T03:02:55.991Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>在大数据时代的背景下, 数据已经成为企业中最重要的资产和生产要素. 如何从数据中发现并挖掘有价值的信息则显得尤为重要. 在项目交付过程中, 数据是平台&#x2F;xx系统的基础, 而作为研发人员经常会面对客户的提数需求, 这部分需求经常具备个性化、临时性、一次性等特点. 如下作为示例:</p><ul><li>产品需求: 系统上线后数据异常原因排查; 新老版本数据融合需求; 数据报表需求等</li><li>运营需求: 某次任务关联的报告数据; 通过系统数据做趋势预测; 数据变动的原因分析等</li><li>客户需求: 提取某次数据上报过程中某省单位的上报详情并出具分析报告; 查一下某个时间点下系统数据的合规率等<br>本系列的文章介绍的数据分析区别于BI工程师【数据分析师】的数据分析, 现实情况中BI们往往在做业务方最关心的数据、最关心的问题等方向的分析, 对于日常过程中的个性化、临时性的数分需求, 一般都是通过研发工程师进行实现. 本系列文章的重点将会以研发工程师【非BI】的视角出发, 介绍如何通过 Python 快速进行数据分析.</li></ul><h1 id="数据分析的流程"><a href="#数据分析的流程" class="headerlink" title="数据分析的流程"></a>数据分析的流程</h1><p>知其然, 需知其所以然. 数据科学是一门复杂的学科, 包括了统计学、数据分析、机器学习在内的多种学科方法, 而数据分析则关注在现有的数据集中, 执行和处理统计分析. 体系化的了解数据分析的流程, 是做数据分析的前置条件.<br>常规的数据分析流程如下:</p><p><img src="/../../images/pandas/01.png" alt="img"></p><ul><li>明确分析思路和目的: 我们接到一个分析任务, 首先要弄清楚我们分析的对象是什么, 要达成怎样的目的, 不能陷于为了分析而分析. 然后, 要熟悉行业和业务, 透彻的理解分析的目的, 构建起分析的角度和体系.</li><li>数据收集: 按照确定的数据分析的思路和框架, 进行数据收集和整合.</li><li>数据处理: 对收集到的数据进行清洗、加工、整理等</li><li>数据分析: 通过分析手段、方法和技巧等对准备好的数据进行探索分析, 从中发现数据的规律.</li><li>数据展现: 通过图表或者报告的形式进行数据到的展现.</li></ul><h1 id="从研发视角看数据分析【数据处理篇】"><a href="#从研发视角看数据分析【数据处理篇】" class="headerlink" title="从研发视角看数据分析【数据处理篇】"></a>从研发视角看数据分析【数据处理篇】</h1><p>作为研发工程师, 在常规的项目中, 假定我们现在接收到的临时性的提数需求已经和产品经理&#x2F;项目经理就数分的思路和目的达成了一致, 并且系统中的数据已经通过南向接口或其他方式进行了收集, 下一步要展开数据处理过程.<br>数据清洗是数据预处理的第一步, 主要是为了解决数据中的缺失值、异常值、重复值等问题. Python提供了pandas库可以帮助我们方便地处理源数据中的缺失值、重复值和异常值, 数据处理可以极大的提升数据的质量, 只有经过处理的数据才可以作为下一步数据分析模型的输入.<br>pandas常用的基本功能如下:</p><ul><li>从Excel、CSV、网页、SQL、剪贴板等文件或工具中读取数据; </li><li>合并多个文件或者电子表格中的数据, 将数据拆分为独立文件; </li><li>数据清洗, 如去重、处理缺失值、填充默认值、补全格式、处理极端值等; </li><li>建立高效的索引; </li><li>支持大体量数据; </li><li>按一定业务逻辑插入计算后的列、删除列; </li><li>灵活方便的数据查询、筛选; </li><li>分组聚合数据, 可独立指定分组后的各字段计算方式; </li><li>数据的转置, 如行转列、列转行变更处理; </li><li>连接数据库, 直接用SQL查询数据并进行处理; </li><li>对时序数据进行分组采样, 如按季、按月、按工作小时, 也可以自定义周期, 如工作日; </li><li>窗口计算, 移动窗口统计、日期移动等; </li><li>灵活的可视化图表输出, 支持所有的统计图形; </li><li>为数据表格增加展示样式, 提高数据识别效率.</li></ul><h1 id="实践应用"><a href="#实践应用" class="headerlink" title="实践应用"></a>实践应用</h1><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><h3 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pandas</span><br></pre></td></tr></table></figure><h3 id="数据集分析"><a href="#数据集分析" class="headerlink" title="数据集分析"></a>数据集分析</h3><p>在准备员工一到四月的考核结果表, 各列说明如下:</p><ul><li>name: 员工的姓名, 这列没有重复值, 一个员工一行</li><li>team: 所在的团队, 这个数据会重复</li><li>一月～四月: 各个月份的考核结果, 可能会有重复值, 缺失值, 异常值</li></ul><img src="/images/pandas/02.png"   style="zoom:20%; " /><h2 id="使用示例"><a href="#使用示例" class="headerlink" title="使用示例"></a>使用示例</h2><h3 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h3><h4 id="检查是否有缺失值"><a href="#检查是否有缺失值" class="headerlink" title="检查是否有缺失值"></a>检查是否有缺失值</h4><p>关键技术: isnull()方法返回值为布尔值, 如果数据存在缺失值, 返回True; 否则, 返回False.</p><img src=/images/pandas/03.png   style="zoom:20%; " /><p>经查, 原始数据中具备缺失值.</p><h4 id="需求案例A-如果该行具有缺失值-则这一行数据被丢弃"><a href="#需求案例A-如果该行具有缺失值-则这一行数据被丢弃" class="headerlink" title="需求案例A: 如果该行具有缺失值, 则这一行数据被丢弃"></a>需求案例A: 如果该行具有缺失值, 则这一行数据被丢弃</h4><p>关键技术: dropna()用于删除含有缺失值的行.</p><img src=/images/pandas/04.png   style="zoom:20%; " /><h4 id="需求案例B-如果该行具有缺失值-则缺失的值使用平均值进行填充"><a href="#需求案例B-如果该行具有缺失值-则缺失的值使用平均值进行填充" class="headerlink" title="需求案例B: 如果该行具有缺失值, 则缺失的值使用平均值进行填充"></a>需求案例B: 如果该行具有缺失值, 则缺失的值使用平均值进行填充</h4><p>关键技术: fillna()方法用于填充含有缺失值的行.mean()方法用于求改行的平均值.</p><img src=/images/pandas/05.png   style="zoom:20%; " /><h3 id="重复值处理"><a href="#重复值处理" class="headerlink" title="重复值处理"></a>重复值处理</h3><h4 id="检查是否有重复值"><a href="#检查是否有重复值" class="headerlink" title="检查是否有重复值"></a>检查是否有重复值</h4><p>关键技术: duplicated()方法检测冗余的行或列, 默认是判断全部列中的值是否全部重复, 并返回布尔类型的结果. 对于完全没有重复的行, 返回值为False. 对于有重复值的行, 第一次出现重复的那一行返回False, 其余的返回True.</p><img src=/images/pandas/06.png   style="zoom:20%; " /><h4 id="需求案例C-如果该行有重复值则丢弃该行数据"><a href="#需求案例C-如果该行有重复值则丢弃该行数据" class="headerlink" title="需求案例C: 如果该行有重复值则丢弃该行数据"></a>需求案例C: 如果该行有重复值则丢弃该行数据</h4><p>关键技术: drop_duplicates()删除重复的行.</p><img src=/images/pandas/07.png   style="zoom:20%; " /><h3 id="异常值检测和处理"><a href="#异常值检测和处理" class="headerlink" title="异常值检测和处理"></a>异常值检测和处理</h3><h4 id="检查是否有异常值"><a href="#检查是否有异常值" class="headerlink" title="检查是否有异常值"></a>检查是否有异常值</h4><p>关键技术:query()方法查询数据中是否有异常值, 用于在 DataFrame 中执行类似于 SQL 的查询的工具, 支持简单查询, 逻辑运算查询, 字符串查询等.</p><img src=/images/pandas/08.png   style="zoom:20%; " /><h3 id="输出新的文件"><a href="#输出新的文件" class="headerlink" title="输出新的文件"></a>输出新的文件</h3><h4 id="需求案例D-根据描述输出报告"><a href="#需求案例D-根据描述输出报告" class="headerlink" title="需求案例D: 根据描述输出报告"></a>需求案例D: 根据描述输出报告</h4><p>需求描述: 将原始数据根据姓名进行分组, 缺失值和异常值默认按照0进行统计, 计算每个人的平均分并从大到小进行排序, 输出内容到 excel.<br>代码:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 引入Pandas库</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取excel内容</span></span><br><span class="line"></span><br><span class="line">df = pd.read_excel(<span class="string">&quot;./数据集/team.xlsx&quot;</span>, )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用 0 填充缺失值</span></span><br><span class="line"></span><br><span class="line">df = df.fillna(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除重复的行</span></span><br><span class="line"></span><br><span class="line">df = df.drop_duplicates().copy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 缺失值和异常值默认按照0进行填充</span></span><br><span class="line"></span><br><span class="line">df[[<span class="string">&quot;一月&quot;</span>, <span class="string">&quot;二月&quot;</span>, <span class="string">&quot;三月&quot;</span>, <span class="string">&quot;四月&quot;</span>]] = df[[<span class="string">&quot;一月&quot;</span>, <span class="string">&quot;二月&quot;</span>, <span class="string">&quot;三月&quot;</span>, <span class="string">&quot;四月&quot;</span>]].applymap(<span class="keyword">lambda</span> x: <span class="number">0</span> <span class="keyword">if</span> x &gt; <span class="number">100</span> <span class="keyword">or</span> x &lt; <span class="number">0</span> <span class="keyword">else</span> x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 增加一列, 平均值</span></span><br><span class="line"></span><br><span class="line">df[<span class="string">&#x27;平均值&#x27;</span>] = df[[<span class="string">&quot;一月&quot;</span>, <span class="string">&quot;二月&quot;</span>, <span class="string">&quot;三月&quot;</span>, <span class="string">&quot;四月&quot;</span>]].mean(axis=<span class="number">1</span>).<span class="built_in">round</span>(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 按照平均值排序</span></span><br><span class="line"></span><br><span class="line">df = df.sort_values([<span class="string">&#x27;平均值&#x27;</span>], ascending=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将数据输出到Excel文件中</span></span><br><span class="line"></span><br><span class="line">df.to_excel(<span class="string">&#x27;./output.xlsx&#x27;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p>输出的excel结果如下:</p><img src=/images/pandas/09.png   style="zoom:20%; " /><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文简单介绍了数据分析的流程以及如何做数据的预处理. 利用几个示例对工作中常见的操作进行了说明, 从代码的层面可以看出, 利用 Python 进行数据分析的操作会更加的灵活快捷方便, 尤其是在临时性的需求面前, 会大大节约我们的时间和资源成本.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;在大数据时代的背景下, 数据已经成为企业中最重要的资产和生产要素. 如何从数据中发现并挖掘有价值的信息则显得尤为重要. 在项目交付过程中, </summary>
      
    
    
    
    <category term="数据科学" scheme="https://champion-yang.github.io/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
    <category term="数据处理" scheme="https://champion-yang.github.io/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    
    
    <category term="Pandas" scheme="https://champion-yang.github.io/tags/Pandas/"/>
    
  </entry>
  
  <entry>
    <title>备考系统架构师</title>
    <link href="https://champion-yang.github.io/2024/07/04/%E5%A4%87%E8%80%83%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E5%B8%88/"/>
    <id>https://champion-yang.github.io/2024/07/04/%E5%A4%87%E8%80%83%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E5%B8%88/</id>
    <published>2024-07-04T01:31:28.000Z</published>
    <updated>2024-07-04T08:43:13.335Z</updated>
    
    
    
    
    <category term="系统架构师" scheme="https://champion-yang.github.io/categories/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E5%B8%88/"/>
    
    
    <category term="架构" scheme="https://champion-yang.github.io/tags/%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>明朝那些事</title>
    <link href="https://champion-yang.github.io/2024/07/04/%E6%98%8E%E6%9C%9D%E9%82%A3%E4%BA%9B%E4%BA%8B/"/>
    <id>https://champion-yang.github.io/2024/07/04/%E6%98%8E%E6%9C%9D%E9%82%A3%E4%BA%9B%E4%BA%8B/</id>
    <published>2024-07-04T01:31:28.000Z</published>
    <updated>2024-07-04T08:43:26.683Z</updated>
    
    <content type="html"><![CDATA[<p>这是测试信息</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;这是测试信息&lt;/p&gt;
</summary>
      
    
    
    
    <category term="读书" scheme="https://champion-yang.github.io/categories/%E8%AF%BB%E4%B9%A6/"/>
    
    
    <category term="书籍" scheme="https://champion-yang.github.io/tags/%E4%B9%A6%E7%B1%8D/"/>
    
  </entry>
  
</feed>
